\item \points{3c}

Implement the \texttt{update} method of the \texttt{DPO} class. This should minimize the DPO loss described above.

Afterwards run the following command to train the DPO model using the provided preference data:

\begin{lstlisting}
$ python run_dpo.py
\end{lstlisting}